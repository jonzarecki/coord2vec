{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperations with pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))\n",
    "sys.path.insert(0, os.path.join(parent_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/morpheus/coord2vec_noam/coord2vec/common/parallel/multiproc_util.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from unittest import TestCase\n",
    "import re\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from coord2vec.config import BUILDINGS_FEATURES_TABLE\n",
    "from coord2vec.feature_extraction.feature_bundles import karka_bundle_features, create_building_features\n",
    "from coord2vec.feature_extraction.features_builders import FeaturesBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_data(get_full_data=True): # -> Tuple[Tuple[float, float], pd.DataFrame, Any]:\n",
    "    server_csv_filder_path = \"/data/home/morpheus/coord2vec_noam/coord2vec/evaluation/tasks/house_pricing\"\n",
    "    if get_full_data:\n",
    "        csv_path = f\"{server_csv_filder_path}/Housing price in Beijing.csv\"\n",
    "    else:\n",
    "        csv_path = f\"{server_csv_filder_path}/Housing price in Beijing small.csv\"\n",
    "    df = pd.read_csv(csv_path, engine='python')\n",
    "#     print(df)\n",
    "    df['coord'] = df.apply(lambda row: tuple(row[['Lng', 'Lat']].values), axis=1)\n",
    "    features = df[[\"DOM\", \"followers\", \"square\" ,\"livingRoom\", \"drawingRoom\", \"kitchen\", \"bathRoom\",\n",
    "                  \"floor\", \"buildingType\", \"constructionTime\", \"renovationCondition\", \"buildingStructure\", \"ladderRatio\",\n",
    "                  \"elevator\", \"fiveYearsProperty\", \"subway\", \"district\", \"communityAverage\", \"coord\", \"totalPrice\"]]\n",
    "    # in features all csv exept: 'url', 'id', 'Lng', 'Lat', 'coord', \"Cid\", \"tradeTime\", \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_features = get_csv_data(get_full_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generic clean funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_clean_col(df, clean_funcs):\n",
    "    ''' df - data frame\n",
    "        cols - list of strings contains cols that should be cleaned\n",
    "        clean_funcs - list of funcs that clean cols that should be cleand in df \n",
    "    '''\n",
    "    for i, col in enumerate(clean_funcs):\n",
    "        df = clean_funcs[i](df)\n",
    "    cleaned_df = df.fillna(0)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean floor column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: floor, dtype: object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some floors are not writen well\n",
    "csv_features[\"floor\"][csv_features[\"floor\"].apply(lambda floor: len(floor.split()))==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_floor_col(df):\n",
    "    # remove data points with no complete data\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df = cleaned_df[cleaned_df[\"floor\"].apply(lambda floor: len(floor.split()))==2]\n",
    "    cleaned_df[\"floor\"] = cleaned_df[\"floor\"].apply(lambda floor: floor.split()[1])\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_floor_col = clean_floor_col(csv_features)\n",
    "len(cleaned_floor_col), len(csv_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean constructionTime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     δ֪\n",
       "82     δ֪\n",
       "101    δ֪\n",
       "158    δ֪\n",
       "160    δ֪\n",
       "189    δ֪\n",
       "251    δ֪\n",
       "272    δ֪\n",
       "293    δ֪\n",
       "346    δ֪\n",
       "375    δ֪\n",
       "455    δ֪\n",
       "483    δ֪\n",
       "496    δ֪\n",
       "553    δ֪\n",
       "578    δ֪\n",
       "579    δ֪\n",
       "704    δ֪\n",
       "742    δ֪\n",
       "771    δ֪\n",
       "788    δ֪\n",
       "826    δ֪\n",
       "842    δ֪\n",
       "949    δ֪\n",
       "955    δ֪\n",
       "Name: constructionTime, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some constructionTime are not numeric\n",
    "csv_features[csv_features['constructionTime'].apply(lambda time : not time.isnumeric())]['constructionTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_constructionTime_col(df):\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df['constructionTime'][cleaned_df['constructionTime'].apply(lambda time : not time.isnumeric())] = 0\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the data using the generic clean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/coord2vec/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "clean_funcs = [clean_floor_col, clean_constructionTime_col] # can add function if needed\n",
    "cleaned_features = generic_clean_col(csv_features, clean_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get geographical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = cleaned_features[\"coord\"].values\n",
    "unique_coords = cleaned_features[\"coord\"].unique()\n",
    "shapely_coords_unique = [Point(coord[0], coord[1]) for coord in unique_coords]\n",
    "\n",
    "coord2coord_id = {coord:i for i, coord in enumerate(cleaned_features[\"coord\"].unique())}\n",
    "# test - len(cleaned_features[\"coord\"].unique()) == len(coord2coord_id)\n",
    "\n",
    "cleaned_features[\"coord_id\"] = cleaned_features[\"coord\"].apply(lambda coord: coord2coord_id[coord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "geo_feats = create_building_features(karka_bundle_features)\n",
    "builder = FeaturesBuilder(geo_feats, cache_table=BUILDINGS_FEATURES_TABLE)\n",
    "gdf = GeoDataFrame(pd.DataFrame({'geom': shapely_coords_unique}), geometry='geom')\n",
    "geo_results = builder.transform(gdf.geometry)\n",
    "geo_results = geo_results.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 693\n",
      "35 34\n",
      "True True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['DOM', 'followers', 'square', 'livingRoom', 'drawingRoom', 'kitchen',\n",
       "       'bathRoom', 'floor', 'buildingType', 'constructionTime',\n",
       "       'renovationCondition', 'buildingStructure', 'ladderRatio', 'elevator',\n",
       "       'fiveYearsProperty', 'subway', 'district', 'communityAverage', 'coord',\n",
       "       'totalPrice', 'coord_id', 'index', 'distance_to_major_road_100m',\n",
       "       'length_of_major_road_100m', 'area_of_nearest_major_road_100m',\n",
       "       'distance_to_major_road_250m', 'length_of_major_road_250m',\n",
       "       'area_of_nearest_major_road_250m', 'distance_to_major_road_500m',\n",
       "       'length_of_major_road_500m', 'area_of_nearest_major_road_500m',\n",
       "       'distance_to_major_road_1000m', 'length_of_major_road_1000m',\n",
       "       'area_of_nearest_major_road_1000m', 'distance_to_minor_road_50m',\n",
       "       'length_of_minor_road_50m', 'area_of_nearest_minor_road_50m',\n",
       "       'distance_to_minor_road_100m', 'length_of_minor_road_100m',\n",
       "       'area_of_nearest_minor_road_100m', 'distance_to_minor_road_250m',\n",
       "       'length_of_minor_road_250m', 'area_of_nearest_minor_road_250m',\n",
       "       'distance_to_building_50m', 'number_of_building_50m',\n",
       "       'area_of_building_50m', 'area_of_nearest_building_50m',\n",
       "       'distance_to_building_100m', 'number_of_building_100m',\n",
       "       'area_of_building_100m', 'area_of_nearest_building_100m',\n",
       "       'distance_to_building_250m', 'number_of_building_250m',\n",
       "       'area_of_building_250m', 'area_of_nearest_building_250m',\n",
       "       'area_of_building_0m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(geo_results.shape[0], gdf.shape[0])\n",
    "print(geo_results.shape[1], len(builder.all_feat_names))\n",
    "print(\"index\" in geo_results.columns, \"coord_id\" in cleaned_features.columns)\n",
    "all_features = cleaned_features.merge(geo_results,left_on='coord_id', right_on='index', how='left')\n",
    "all_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit a simple linear regression on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24208.409242781807]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = all_features.drop(columns=[\"coord\", \"coord_id\", \"index\", \"totalPrice\"]).values\n",
    "y = all_features['totalPrice'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "models = [LinearRegression()]\n",
    "scores = []\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    scores.append(mean_squared_error(y_test, y_test_pred))\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coord2vec] *",
   "language": "python",
   "name": "conda-env-coord2vec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
