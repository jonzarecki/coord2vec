{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Preperations with pycharm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))\n",
    "sys.path.insert(0, os.path.join(parent_dir))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from unittest import TestCase\n",
    "import re\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "from coord2vec.config import BUILDINGS_FEATURES_TABLE\n",
    "from coord2vec.feature_extraction.feature_bundles import karka_bundle_features, create_building_features\n",
    "from coord2vec.feature_extraction.features_builders import FeaturesBuilder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get csv data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_csv_data(use_full_dataset=True): # -> Tuple[Tuple[float, float], pd.DataFrame, Any]:\n",
    "    server_csv_filder_path = \"/data/home/morpheus/coord2vec_noam/coord2vec/evaluation/tasks/house_pricing\"\n",
    "    if use_full_dataset:\n",
    "        csv_path = f\"{server_csv_filder_path}/Housing price in Beijing.csv\"\n",
    "    else:\n",
    "        small_or_medium = \"medium\"\n",
    "        csv_path = f\"{server_csv_filder_path}/Housing price in Beijing {small_or_medium}.csv\"\n",
    "    df = pd.read_csv(csv_path, engine='python')\n",
    "#     print(df)\n",
    "    df['coord'] = df.apply(lambda row: tuple(row[['Lng', 'Lat']].values), axis=1)\n",
    "    features = df[[\"DOM\", \"followers\", \"square\" ,\"livingRoom\", \"drawingRoom\", \"kitchen\", \"bathRoom\",\n",
    "                  \"floor\", \"buildingType\", \"constructionTime\", \"renovationCondition\", \"buildingStructure\", \"ladderRatio\",\n",
    "                  \"elevator\", \"fiveYearsProperty\", \"subway\", \"district\", \"communityAverage\", \"coord\", \"totalPrice\"]]\n",
    "    # in features all csv exept: 'url', 'id', 'Lng', 'Lat', 'coord', \"Cid\", \"tradeTime\", \n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_full_dataset = True\n",
    "csv_features = get_csv_data(use_full_dataset=use_full_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## cleaning the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### generic clean funcion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generic_clean_col(df, clean_funcs):\n",
    "    ''' df - data frame\n",
    "        cols - list of strings contains cols that should be cleaned\n",
    "        clean_funcs - list of funcs that clean cols that should be cleand in df \n",
    "    '''\n",
    "    for i, col in enumerate(clean_funcs):\n",
    "        df = clean_funcs[i](df)\n",
    "    cleaned_df = df.fillna(0)\n",
    "    return cleaned_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### clean floor column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# some floors are not writen well\n",
    "csv_features[\"floor\"][csv_features[\"floor\"].apply(lambda floor: len(floor.split()))==1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_floor_col(df):\n",
    "    # remove data points with no complete data\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df = cleaned_df[cleaned_df[\"floor\"].apply(lambda floor: len(floor.split()))==2]\n",
    "    cleaned_df[\"floor\"] = cleaned_df[\"floor\"].apply(lambda floor: floor.split()[1])\n",
    "    return cleaned_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleaned_floor_col = clean_floor_col(csv_features)\n",
    "len(cleaned_floor_col), len(csv_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### clean constructionTime column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# some constructionTime are not numeric\n",
    "csv_features[csv_features['constructionTime'].apply(lambda time : not time.isnumeric())]['constructionTime']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_constructionTime_col(df):\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df['constructionTime'][cleaned_df['constructionTime'].apply(lambda time : not time.isnumeric())] = 0\n",
    "    return cleaned_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### clean the data using the generic clean function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean_funcs = [clean_floor_col, clean_constructionTime_col] # can add function if needed\n",
    "cleaned_features = generic_clean_col(csv_features, clean_funcs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get geographical data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# coords = cleaned_features[\"coord\"].values\n",
    "unique_coords = cleaned_features[\"coord\"].unique()\n",
    "shapely_coords_unique = [Point(coord[0], coord[1]) for coord in unique_coords]\n",
    "\n",
    "coord2coord_id = {coord:i for i, coord in enumerate(cleaned_features[\"coord\"].unique())}\n",
    "# test - len(cleaned_features[\"coord\"].unique()) == len(coord2coord_id)\n",
    "\n",
    "cleaned_features[\"coord_id\"] = cleaned_features[\"coord\"].apply(lambda coord: coord2coord_id[coord])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "geo_feats = create_building_features(karka_bundle_features)\n",
    "builder = FeaturesBuilder(geo_feats, cache_table=BUILDINGS_FEATURES_TABLE)\n",
    "gdf = GeoDataFrame(pd.DataFrame({'geom': shapely_coords_unique}), geometry='geom')\n",
    "geo_results_list = []\n",
    "batch_size = 10000\n",
    "n_samples = len(gdf.geometry)\n",
    "calculate_geo_features_with_batches = use_full_dataset\n",
    "if (not calculate_geo_features_with_batches) or (n_samples<=batch_size):\n",
    "    geo_results = builder.transform(gdf.geometry)\n",
    "else:\n",
    "    for batch_start_ind in range(0, n_samples, batch_size):\n",
    "        batch_end_ind = batch_start_ind+batch_size if batch_start_ind+batch_size<n_samples else n_samples\n",
    "        geo_results_list.append(builder.transform(gdf.geometry[batch_start_ind:batch_end_ind]))\n",
    "    geo_results = pd.concat(geo_results_list)\n",
    "    geo_results = geo_results.reset_index(drop=True)\n",
    "\n",
    "# print(len(geo_results[0]) + len(geo_results[0]) + len(geo_results[0]), n_samples ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(geo_results.shape[0], gdf.shape[0])\n",
    "# print(geo_results.shape[1], len(builder.all_feat_names))\n",
    "# print(\"index\" in geo_results.columns, \"coord_id\" in cleaned_features.columns)\n",
    "all_features = cleaned_features.merge(geo_results,left_on='coord_id', right_index=True, how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fit a simple linear regression on the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = all_features.drop(columns=[\"coord\", \"coord_id\", \"totalPrice\"]).values\n",
    "y = all_features['totalPrice'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "n_cat_iter = 150\n",
    "models = [LinearRegression(),\n",
    "          CatBoostRegressor(iterations=n_cat_iter, learning_rate=1, depth=3)]\n",
    "scores = []\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    scores.append(mean_squared_error(y_test, y_test_pred))\n",
    "print(\"mean price - \", np.mean(y_test))\n",
    "print(f\"MSE: linear regression - {scores[0]}, catboost - {scores[1]}\")\n",
    "print(f\"RMSE: linear regression - {np.sqrt(scores[0])}, catboost - {np.sqrt(scores[1])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coord2vec] *",
   "language": "python",
   "name": "conda-env-coord2vec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}