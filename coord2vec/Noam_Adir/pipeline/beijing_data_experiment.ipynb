{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperations with pycharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))\n",
    "sys.path.insert(0, os.path.join(parent_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import TestCase\n",
    "import re\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from coord2vec.config import BUILDINGS_FEATURES_TABLE\n",
    "from coord2vec.feature_extraction.feature_bundles import karka_bundle_features, create_building_features\n",
    "from coord2vec.feature_extraction.features_builders import FeaturesBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_data(): # -> Tuple[Tuple[float, float], pd.DataFrame, Any]:\n",
    "\n",
    "    server_csv_path = \"/data/home/morpheus/coord2vec_noam/coord2vec/evaluation/tasks/house_pricing/Housing price in Beijing.csv\"\n",
    "    df = pd.read_csv(server_csv_path, engine='python')\n",
    "#     print(df)\n",
    "    df['coord'] = df.apply(lambda row: tuple(row[['Lng', 'Lat']].values), axis=1)\n",
    "    features = df[[\"DOM\", \"followers\", \"square\" ,\"livingRoom\", \"drawingRoom\", \"kitchen\", \"bathRoom\",\n",
    "                  \"floor\", \"buildingType\", \"constructionTime\", \"renovationCondition\", \"buildingStructure\", \"ladderRatio\",\n",
    "                  \"elevator\", \"fiveYearsProperty\", \"subway\", \"district\", \"communityAverage\", \"coord\", \"totalPrice\"]]\n",
    "    # in features all csv exept: 'url', 'id', 'Lng', 'Lat', 'coord', \"Cid\", \"tradeTime\", \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_features = get_csv_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generic clean funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_clean_col(df, clean_funcs):\n",
    "    ''' df - data frame\n",
    "        cols - list of strings contains cols that should be cleaned\n",
    "        clean_funcs - list of funcs that clean cols that should be cleand in df \n",
    "    '''\n",
    "    for i, col in enumerate(clean_funcs):\n",
    "        df = clean_funcs[i](df)\n",
    "    cleaned_df = df.fillna(0)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean floor column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92235     �ֻ�ṹ\n",
       "92251     �ֻ�ṹ\n",
       "92267     �ֻ�ṹ\n",
       "92270     ��Ͻṹ\n",
       "92297     �ֻ�ṹ\n",
       "92299     ��Ͻṹ\n",
       "92300     �ֻ�ṹ\n",
       "92304     ��Ͻṹ\n",
       "92340     ��Ͻṹ\n",
       "92349     �ֻ�ṹ\n",
       "92356     ��Ͻṹ\n",
       "92398     �ֻ�ṹ\n",
       "92409     ��Ͻṹ\n",
       "92414     �ֻ�ṹ\n",
       "92467     �ֻ�ṹ\n",
       "92520     ��Ͻṹ\n",
       "92610     ��Ͻṹ\n",
       "92660     ��Ͻṹ\n",
       "92814     �ֻ�ṹ\n",
       "92845     �ֻ�ṹ\n",
       "92899     �ֻ�ṹ\n",
       "113275    ��Ͻṹ\n",
       "141376    �ֻ�ṹ\n",
       "208214    ��Ͻṹ\n",
       "220567    ��Ͻṹ\n",
       "220569    ��Ͻṹ\n",
       "220570    ��Ͻṹ\n",
       "220603    ��Ͻṹ\n",
       "224349    �ֻ�ṹ\n",
       "243731    �ֻ�ṹ\n",
       "244054    �ֻ�ṹ\n",
       "245394    �ֻ�ṹ\n",
       "Name: floor, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some floors are not writen well\n",
    "csv_features[\"floor\"][csv_features[\"floor\"].apply(lambda floor: len(floor.split()))==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_floor_col(df):\n",
    "    # remove data points with no complete data\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df = cleaned_df[cleaned_df[\"floor\"].apply(lambda floor: len(floor.split()))==2]\n",
    "    cleaned_df[\"floor\"] = cleaned_df[\"floor\"].apply(lambda floor: floor.split()[1])\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318819, 318851)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_floor_col = clean_floor_col(csv_features)\n",
    "len(cleaned_floor_col), len(csv_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean constructionTime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41        δ֪\n",
       "82        δ֪\n",
       "101       δ֪\n",
       "158       δ֪\n",
       "160       δ֪\n",
       "          ..\n",
       "318825    δ֪\n",
       "318828    δ֪\n",
       "318833    δ֪\n",
       "318839    δ֪\n",
       "318850    δ֪\n",
       "Name: constructionTime, Length: 19283, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some constructionTime are not numeric\n",
    "csv_features[csv_features['constructionTime'].apply(lambda time : not time.isnumeric())]['constructionTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_constructionTime_col(df):\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df[cleaned_df['constructionTime'].apply(lambda time : not time.isnumeric())]['constructionTime'] = 0\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the data using the generic clean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/coord2vec/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "clean_funcs = [clean_floor_col, clean_constructionTime_col] # can add function if needed\n",
    "cleaned_features = generic_clean_col(csv_features, clean_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get geographical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for memory reasons choose only n_choose examples\n",
    "n_choose = 10000\n",
    "cleaned_features = cleaned_features[:n_choose]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking loaded features:   0%|          | 0/34 [00:00<?, ?feature/s]\u001b[A\n",
      "                                                                     \u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Calculating intersection', max=9.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Calculating Features for 10000 geoms', max=27.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserting Features to building_features:   0%|          | 0/27 [00:00<?, ?feature/s]\u001b[A\n",
      "Inserting Features to building_features:   4%|▎         | 1/27 [00:05<02:16,  5.26s/feature]\u001b[A\n",
      "Inserting Features to building_features:   7%|▋         | 2/27 [00:09<02:01,  4.88s/feature]\u001b[A\n",
      "Inserting Features to building_features:  11%|█         | 3/27 [00:13<01:50,  4.61s/feature]\u001b[A\n",
      "Inserting Features to building_features:  15%|█▍        | 4/27 [00:17<01:43,  4.49s/feature]\u001b[A\n",
      "Inserting Features to building_features:  19%|█▊        | 5/27 [00:21<01:35,  4.35s/feature]\u001b[A\n",
      "Inserting Features to building_features:  22%|██▏       | 6/27 [00:25<01:29,  4.24s/feature]\u001b[A\n",
      "Inserting Features to building_features:  26%|██▌       | 7/27 [00:29<01:21,  4.09s/feature]\u001b[A\n",
      "Inserting Features to building_features:  30%|██▉       | 8/27 [00:33<01:16,  4.03s/feature]\u001b[A\n",
      "Inserting Features to building_features:  33%|███▎      | 9/27 [00:36<01:11,  3.98s/feature]\u001b[A\n",
      "Inserting Features to building_features:  37%|███▋      | 10/27 [00:40<01:07,  3.99s/feature]\u001b[A\n",
      "Inserting Features to building_features:  41%|████      | 11/27 [00:44<01:03,  3.96s/feature]\u001b[A\n",
      "Inserting Features to building_features:  44%|████▍     | 12/27 [00:48<00:58,  3.92s/feature]\u001b[A\n",
      "Inserting Features to building_features:  48%|████▊     | 13/27 [00:52<00:53,  3.84s/feature]\u001b[A\n",
      "Inserting Features to building_features:  52%|█████▏    | 14/27 [00:56<00:50,  3.86s/feature]\u001b[A\n",
      "Inserting Features to building_features:  56%|█████▌    | 15/27 [01:00<00:47,  3.92s/feature]\u001b[A\n",
      "Inserting Features to building_features:  59%|█████▉    | 16/27 [01:04<00:43,  3.93s/feature]\u001b[A\n",
      "Inserting Features to building_features:  63%|██████▎   | 17/27 [01:08<00:39,  3.95s/feature]\u001b[A\n",
      "Inserting Features to building_features:  67%|██████▋   | 18/27 [01:12<00:35,  3.99s/feature]\u001b[A\n",
      "Inserting Features to building_features:  70%|███████   | 19/27 [01:16<00:31,  3.99s/feature]\u001b[A\n",
      "Inserting Features to building_features:  74%|███████▍  | 20/27 [01:20<00:27,  3.95s/feature]\u001b[A\n",
      "Inserting Features to building_features:  78%|███████▊  | 21/27 [01:24<00:23,  3.92s/feature]\u001b[A\n",
      "Inserting Features to building_features:  81%|████████▏ | 22/27 [01:27<00:19,  3.91s/feature]\u001b[A\n",
      "Inserting Features to building_features:  85%|████████▌ | 23/27 [01:31<00:15,  3.85s/feature]\u001b[A\n",
      "Inserting Features to building_features:  89%|████████▉ | 24/27 [01:35<00:11,  3.86s/feature]\u001b[A\n",
      "Inserting Features to building_features:  93%|█████████▎| 25/27 [01:39<00:07,  3.87s/feature]\u001b[A\n",
      "Inserting Features to building_features:  96%|█████████▋| 26/27 [01:43<00:03,  3.91s/feature]\u001b[A\n",
      "Inserting Features to building_features: 100%|██████████| 27/27 [01:47<00:00,  3.91s/feature]\u001b[A\n",
      "                                                                                             \u001b[A"
     ]
    }
   ],
   "source": [
    "coords = cleaned_features[\"coord\"].values\n",
    "shapely_coords = [Point(coord[0], coord[1]) for coord in coords]\n",
    "\n",
    "geo_feats = create_building_features(karka_bundle_features)\n",
    "builder = FeaturesBuilder(geo_feats, cache_table=BUILDINGS_FEATURES_TABLE)\n",
    "gdf = GeoDataFrame(pd.DataFrame({'geom': shapely_coords}), geometry='geom')\n",
    "geo_results = builder.transform(gdf.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(geo_results.shape[0], gdf.shape[0])\n",
    "print(geo_results.shape[1], len(builder.all_feat_names))\n",
    "# geo_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88908 10000\n",
      "34 34\n"
     ]
    }
   ],
   "source": [
    "## fit a simple linear regression on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit a simple linear regression on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-64d41ed389f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'totalPrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_features' is not defined"
     ]
    }
   ],
   "source": [
    "X = cleaned_features.values\n",
    "y = cleaned_features['totalPrice'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "models = [LinearRegression()]\n",
    "scores = []\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    scores.append(mean_squared_error(y_test, y_test_pred))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_csv_features = filtered_csv_features.drop(columns=[\"floor\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}